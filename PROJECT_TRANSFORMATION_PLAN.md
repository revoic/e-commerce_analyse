# üöÄ E-Commerce Intelligence Tool - Transformation Plan

**Projekt:** Pernod Ricard Agent ‚Üí Universal E-Commerce Intelligence Tool  
**Version:** 2.0  
**Datum:** 19. Januar 2026  
**Status:** Ready for Implementation  

---

## üìã Executive Summary

### **Projektziel**
Transformation des hardcoded Pernod Ricard Monitoring Tools in eine **generische Multi-Company E-Commerce Intelligence Plattform** mit 100% Fakten-Treue durch ein **7-Layer Anti-Halluzination System**.

### **Key Changes**
- ‚úÖ **Multi-Company Support:** Beliebige Firmennamen analysierbar
- ‚úÖ **Anti-Halluzination:** 7-schichtiges Validierungssystem
- ‚úÖ **Dual-Mode:** Funktioniert mit DB (PostgreSQL) oder ohne (JSON)
- ‚úÖ **Multi-User:** Mehrere gleichzeitige Analysen m√∂glich
- ‚úÖ **History:** Analyse-Historie mit Suchfunktion
- ‚úÖ **EU/DE Fokus:** Spezialisiert auf europ√§ische E-Commerce M√§rkte

### **Scope**
Phase 1-5.3: Production-Ready MVP mit vollst√§ndiger Validierung

**Gesch√§tzter Aufwand:** 64-84 Stunden (8-11 Arbeitstage)

---

## ‚úÖ Finalisierte Entscheidungen

| # | Bereich | Entscheidung | Begr√ºndung |
|---|---------|--------------|------------|
| 1 | **Datenbank** | Dual-Mode (PostgreSQL + JSON Fallback) | Flexibilit√§t, kostenlos nutzbar |
| 2 | **Multi-User** | Ja | Mehrere simultane Analysen m√∂glich |
| 3 | **Beispiel-Daten** | Behalten mit Warning-Banner | Demo-Zwecke, nicht aktuell |
| 4 | **History** | Ja (in DB gespeichert) | Wiederverwendung, Vergleiche |
| 5 | **LLM Model** | gpt-4o-mini (konfigurierbar) | Cost-effective, schnell, upgradef√§hig |
| 6 | **Regionen** | Hardcoded EU/DE mit Info-Banner | Spezialisierung, klarer Fokus |
| 7 | **Deployment** | Direct via Streamlit Cloud | Kein Dev Branch, schnelles Testing |
| 8 | **Projekt-Name** | "ecommerce_intel" | Generisch, beschreibend |
| 9 | **Export** | CSV + JSON | Wie aktuell, ausreichend |
| 10 | **Error Handling** | Weiterlaufen + Details | Graceful degradation, debugging |
| 11 | **Job Processing** | Synchron mit Progress Bar | Einfacher, keine Redis/Celery |
| 12 | **Human Review** | Nein | User kann Quellen selbst pr√ºfen |
| 13 | **Secrets** | GitHub Secrets + Streamlit | Wie bisher, kein .env |

---

## üéØ Hauptfeatures

### **1. Multi-Company Intelligence**
- Firmeneingabe via UI (Text Input)
- Auto-Discovery von Newsroom, LinkedIn, etc.
- Domain-Guessing aus Firmennamen
- Dynamische Google News Queries

### **2. 7-Layer Anti-Halluzination System**

#### **Layer 1: Source Verification**
- Hash-basierte Integrit√§tspr√ºfung
- Volltext-Speicherung
- URL-Verifizierung (optional)

#### **Layer 2: Citation Enforcement ‚≠ê KRITISCH**
- Pflichtfeld `verbatim_quote` f√ºr jedes Signal
- Fuzzy-Matching gegen Quelltext
- Automatische Ablehnung ohne valides Zitat
- Nummerische Werte m√ºssen im Zitat nachweisbar sein

#### **Layer 3: Schema Validation**
- Pydantic Models mit strikter Validierung
- Pflichtfelder: verbatim_quote, source_title, source_url
- Confidence nicht > 0.95 (unrealistisch)
- Metric + Unit bei numeric_value

#### **Layer 4: Confidence Filtering**
- Multi-Tier: Verified (‚â•0.90), High (‚â•0.80), Medium (‚â•0.70)
- Automatische Filterung: Nur ‚â•0.70 in Reports
- Confidence-Badges in UI (üü¢üü°üü†)
- Statistiken √ºber aussortierte Signals

#### **Layer 5: Cross-Reference Validation**
- Sucht nach gleichen Fakten in mehreren Quellen
- Confidence-Boost bei Corroboration (2+ Quellen)
- Confidence-Penalty bei Single-Source

#### **Layer 6: LLM Fact-Checking Pass**
- Zweiter LLM-Call zur Verifizierung
- Status: verified / partially_correct / incorrect / cannot_verify
- Automatische Confidence-Anpassung
- Ablehnung von "incorrect" Signals

#### **Layer 7: Transparent Reporting**
- Jede Aussage mit [n] Quellenangabe
- Vollst√§ndige Quellenliste
- Validierungs-Statistiken im Bericht
- Abschnitt "Datenqualit√§t & Einschr√§nkungen"

**Erwartete Rejection-Rate:** 40-60% (gewollt - Qualit√§t √ºber Quantit√§t)

### **3. User Interface**

#### **Hauptseite - Company Input**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Sidebar                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ üîç Company Analysis           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Firmenname: [________]        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚öôÔ∏è Erweiterte Optionen         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Domain (optional)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Newsroom URL (optional)     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   LinkedIn URL (optional)     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Lookback Days: [14]         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ [üöÄ Analyse starten]          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  ‚ÑπÔ∏è Fokus: EU/DE E-Commerce         ‚îÇ
‚îÇ  ü§ñ Model: gpt-4o-mini              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Main Content                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Welcome Screen                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (wenn kein Firmenname)        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  üìö Letzte Analysen (History)       ‚îÇ
‚îÇ  ‚Ä¢ Coca-Cola (vor 2h) ‚úÖ           ‚îÇ
‚îÇ  ‚Ä¢ Unilever (vor 1 Tag) ‚úÖ         ‚îÇ
‚îÇ  ‚Ä¢ LVMH (vor 3 Tagen) ‚úÖ           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **W√§hrend Analyse - Progress Tracking**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Analysiere: Coca-Cola               ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 60%              ‚îÇ
‚îÇ üß† Generiere Signale...             ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ Abgeschlossene Schritte:            ‚îÇ
‚îÇ ‚úÖ Quellen entdeckt (45 gefunden)   ‚îÇ
‚îÇ ‚úÖ Inhalte extrahiert (38 valid)    ‚îÇ
‚îÇ ‚è≥ Signale werden generiert...      ‚îÇ
‚îÇ ‚è∏Ô∏è Bericht wird erstellt            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **Results Display**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Coca-Cola ‚Äî E-Commerce Intelligence ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ üìä KPIs                             ‚îÇ
‚îÇ ‚Ä¢ Signale: 12 (8 verified)          ‚îÇ
‚îÇ ‚Ä¢ Quellen: 38 (EU: 28)              ‚îÇ
‚îÇ ‚Ä¢ Rejection Rate: 47%               ‚îÇ
‚îÇ ‚Ä¢ Avg. Confidence: 0.82             ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ üìù Bericht                          ‚îÇ
‚îÇ [Executive Summary...]              ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ üîç Signale (filterable)             ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ üü¢ E-Commerce Umsatz DE      ‚îÇ    ‚îÇ
‚îÇ ‚îÇ Confidence: 0.92             ‚îÇ    ‚îÇ
‚îÇ ‚îÇ Zitat: "Umsatz stieg um..." ‚îÇ    ‚îÇ
‚îÇ ‚îÇ ‚úÖ Verified                  ‚îÇ    ‚îÇ
‚îÇ ‚îÇ üìö 2 weitere Quellen         ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ üìö Quellen (38)                     ‚îÇ
‚îÇ [Liste mit Links...]                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üóÇÔ∏è Neue Dateistruktur

```
ecommerce_intel/                    # Umbenannt von pernod_ricard_agent_repo_full
‚îÇ
‚îú‚îÄ‚îÄ app.py                          # Komplett √ºberarbeitet: Multi-Company UI
‚îú‚îÄ‚îÄ db.py                           # Angepasst: DB + JSON Fallback
‚îú‚îÄ‚îÄ models.sql                      # Erweitert: companies, analyses Tabellen
‚îú‚îÄ‚îÄ requirements.txt                # Neue Dependencies
‚îú‚îÄ‚îÄ README.md                       # Neu geschrieben
‚îú‚îÄ‚îÄ .gitignore                      # Bleibt
‚îú‚îÄ‚îÄ Dockerfile                      # Angepasst
‚îÇ
‚îú‚îÄ‚îÄ core/                           # NEU: Business Logic
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py                  # CompanyIntelligenceScraper Klasse
‚îÇ   ‚îú‚îÄ‚îÄ extractor.py                # Generisch + Validation
‚îÇ   ‚îú‚îÄ‚îÄ report_generator.py         # Dynamische Reports
‚îÇ   ‚îî‚îÄ‚îÄ analysis_engine.py          # Orchestrierung mit Progress
‚îÇ
‚îú‚îÄ‚îÄ validators/                     # NEU: 7-Layer Validation
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ citation_validator.py       # Layer 2: Zitat-Pr√ºfung (KRITISCH)
‚îÇ   ‚îú‚îÄ‚îÄ confidence_filter.py        # Layer 4: Confidence Thresholds
‚îÇ   ‚îú‚îÄ‚îÄ cross_reference.py          # Layer 5: Multi-Source Check
‚îÇ   ‚îî‚îÄ‚îÄ llm_fact_checker.py         # Layer 6: LLM Fact-Check
‚îÇ
‚îú‚îÄ‚îÄ models/                         # NEU: Data Models
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ signal_models.py            # Pydantic mit strikter Validation
‚îÇ
‚îú‚îÄ‚îÄ prompts/                        # Erweitert
‚îÇ   ‚îú‚îÄ‚îÄ extract_prompt.txt          # Anti-Hallucination Rules
‚îÇ   ‚îî‚îÄ‚îÄ report_prompt.txt           # NEU: Report Template
‚îÇ
‚îú‚îÄ‚îÄ utils/                          # NEU: Helpers
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ text_utils.py               # Normalisierung, Cleaning
‚îÇ   ‚îî‚îÄ‚îÄ url_utils.py                # Domain-Guessing, URL-Parsing
‚îÇ
‚îú‚îÄ‚îÄ scripts/                        
‚îÇ   ‚îú‚îÄ‚îÄ init_db.py                  # NEU: DB Initialization
‚îÇ   ‚îî‚îÄ‚îÄ test_company.py             # NEU: Quick Testing Script
‚îÇ
‚îú‚îÄ‚îÄ tests/                          # Erweitert
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_citation_validator.py  # NEU
‚îÇ   ‚îú‚îÄ‚îÄ test_confidence_filter.py   # NEU
‚îÇ   ‚îú‚îÄ‚îÄ test_cross_reference.py     # NEU
‚îÇ   ‚îú‚îÄ‚îÄ test_scraper.py             # NEU
‚îÇ   ‚îî‚îÄ‚îÄ test_extractor.py           # Erweitert
‚îÇ
‚îî‚îÄ‚îÄ data/                           # Bleibt
    ‚îú‚îÄ‚îÄ pernod_ricard_example.json  # Umbenannt mit Warning-Banner
    ‚îî‚îÄ‚îÄ .gitkeep

# GEL√ñSCHT/VERSCHOBEN:
‚ùå scraper.py (alt)                 ‚Üí core/scraper.py
‚ùå extractor.py (alt)                ‚Üí core/extractor.py
‚ùå scripts/build_json.py             ‚Üí core/analysis_engine.py
‚ùå scripts/run_agent.py              ‚Üí obsolete
```

---

## üìê Datenbank-Schema

### **Neue Tabellen**

```sql
-- Companies: Multi-Company Support
CREATE TABLE IF NOT EXISTS companies (
  id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
  name text NOT NULL,
  domain text,
  newsroom_url text,
  linkedin_url text,
  config jsonb DEFAULT '{}',
  created_at timestamptz DEFAULT now(),
  updated_at timestamptz DEFAULT now(),
  UNIQUE(name, domain)
);

-- Analyses: Job-Tracking & History
CREATE TABLE IF NOT EXISTS analyses (
  id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
  company_id uuid REFERENCES companies(id) ON DELETE CASCADE,
  status text DEFAULT 'pending',  -- pending, running, completed, failed
  progress jsonb DEFAULT '{}',
  lookback_days int DEFAULT 14,
  max_sources int DEFAULT 50,
  started_at timestamptz,
  completed_at timestamptz,
  error_message text,
  result_json jsonb,  -- Cached results for fast display
  validation_stats jsonb,  -- Rejection rate, confidence distribution
  created_at timestamptz DEFAULT now(),
  INDEX idx_company_created (company_id, created_at DESC)
);

-- Sources: Linked to analysis
CREATE TABLE IF NOT EXISTS sources (
  id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
  analysis_id uuid REFERENCES analyses(id) ON DELETE CASCADE,
  url text NOT NULL,
  title text,
  source_type text,  -- newsroom, gnews, linkedin
  published_at timestamptz,
  language text,
  raw_text text NOT NULL,
  text_hash text NOT NULL,
  fetch_timestamp timestamptz DEFAULT now(),
  http_status_code int,
  is_eu_source boolean DEFAULT false,
  has_ecommerce_keywords boolean DEFAULT false,
  created_at timestamptz DEFAULT now(),
  UNIQUE(analysis_id, text_hash)
);
CREATE INDEX idx_sources_analysis ON sources(analysis_id);
CREATE INDEX idx_sources_text_search ON sources USING gin(to_tsvector('german', raw_text));

-- Signals: Linked to analysis
CREATE TABLE IF NOT EXISTS signals (
  id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
  analysis_id uuid REFERENCES analyses(id) ON DELETE CASCADE,
  source_id uuid REFERENCES sources(id),
  type text,
  value jsonb,
  verbatim_quote text NOT NULL,  -- NEW: Required!
  confidence numeric CHECK (confidence >= 0 AND confidence <= 1),
  fact_check_status text,  -- verified, partially_correct, incorrect, cannot_verify
  corroboration_count int DEFAULT 0,
  detected_at timestamptz DEFAULT now()
);
CREATE INDEX idx_signals_analysis ON signals(analysis_id);
CREATE INDEX idx_signals_confidence ON signals(confidence DESC);
```

---

## üîß Technische Spezifikationen

### **Dependencies (requirements.txt)**

```txt
# Existing
requests>=2.31
beautifulsoup4>=4.12
feedparser>=6.0.10
python-dateutil>=2.8.2
python-dotenv>=1.0.1
streamlit>=1.30.0
pandas>=2.0.0
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0

# OpenAI
openai>=1.30.0

# NEW: Validation & Processing
pydantic>=2.5.0
readability-lxml>=0.8.1
httpx>=0.25.0

# NEW: Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0

# Optional: Enhanced features
plotly>=5.18.0  # For charts
```

### **Environment Variables**

```bash
# Required
OPENAI_API_KEY=sk-...

# Optional - Database
DATABASE_URL=postgresql://user:pass@host:5432/dbname

# Optional - Configuration
OPENAI_MODEL=gpt-4o-mini  # Default if not set
APP_TITLE=E-Commerce Intelligence Tool
DEFAULT_LOOKBACK_DAYS=14
MAX_CONCURRENT_ANALYSES=5

# Optional - Features
ENABLE_URL_VERIFICATION=false
MIN_CONFIDENCE_THRESHOLD=0.70
```

### **Streamlit Secrets (secrets.toml)**

```toml
OPENAI_API_KEY = "sk-..."
DATABASE_URL = "postgresql://..."  # Optional
OPENAI_MODEL = "gpt-4o-mini"
```

### **GitHub Secrets**

```
OPENAI_API_KEY
DATABASE_URL (optional)
OPENAI_MODEL (optional)
```

---

## üìÖ Implementierungs-Roadmap

### **Sprint 1: Foundation (Tag 1-2, ~12-16h)**

**Ziel:** Basis-Infrastruktur f√ºr Multi-Company

#### Aufgaben:
1. ‚úÖ Repository umbenennen ‚Üí `ecommerce_intel`
2. ‚úÖ Neue Ordnerstruktur anlegen (`core/`, `validators/`, `models/`, `utils/`)
3. ‚úÖ `models.sql` erweitern (companies, analyses Tabellen)
4. ‚úÖ `db.py` anpassen:
   - DB-Connection mit Fallback
   - `init_db()` f√ºr neue Tabellen
   - Helper-Funktionen (create_company, create_analysis, etc.)
5. ‚úÖ `utils/url_utils.py`:
   - Domain-Guessing aus Firmennamen
   - URL-Normalisierung
   - EU-URL Detection
6. ‚úÖ `utils/text_utils.py`:
   - Text-Normalisierung
   - Hash-Funktionen
   - Cleaning-Helpers
7. ‚úÖ `requirements.txt` aktualisieren

**Deliverable:** Infrastruktur steht, DB l√§uft

---

### **Sprint 2: Core Scraper Logic (Tag 2-3, ~14-18h)**

**Ziel:** Generischer Scraper f√ºr beliebige Firmen

#### Aufgaben:
1. ‚úÖ `core/scraper.py` - `CompanyIntelligenceScraper` Klasse:
   - `__init__(company_name, config)`
   - `discover_all_sources()` Orchestrator
   - `_discover_google_news()` - EU Editionen + E-Commerce Queries
   - `_discover_linkedin_via_gnews()` - site:linkedin.com
   - `_discover_linkedin_direct()` - Wenn URL gegeben
   - `_auto_discover_newsroom()` - Try common patterns
   - `_scrape_newsroom_index()` - Parse newsroom pages
   - `enrich_sources()` - Fetch & extract full text
   - `_build_ecommerce_queries()` - Dynamic query templates
2. ‚úÖ `core/scraper.py` - Error Handling:
   - Graceful degradation (1 Source-Type fails ‚Üí continue)
   - Detailed error messages
   - Rate limiting (exponential backoff)
3. ‚úÖ Tests: `tests/test_scraper.py`
   - Test domain guessing
   - Test query building
   - Test newsroom auto-discovery

**Deliverable:** Scraper funktioniert f√ºr beliebige Firmen

---

### **Sprint 3: Validation Layer (Tag 3-4, ~16-20h)**

**Ziel:** Anti-Halluzination System implementieren

#### Aufgaben:
1. ‚úÖ `models/signal_models.py`:
   - `SignalValue` Pydantic Model
   - `Signal` Pydantic Model (mit verbatim_quote!)
   - `ExtractionResult` Model
   - Strikte Validators
2. ‚úÖ `validators/citation_validator.py` ‚≠ê **KRITISCH**:
   - `CitationValidator` Klasse
   - `validate_signal()` - Pr√ºft einzelnes Signal
   - `_fuzzy_contains()` - Fuzzy-Matching gegen Quelltext
   - `_validate_number_in_text()` - Zahlen-Verifizierung
   - `validate_all_signals()` - Batch-Processing
   - Logging rejected signals
3. ‚úÖ `validators/confidence_filter.py`:
   - `ConfidenceFilter` Klasse
   - Multi-Tier thresholds (0.70, 0.80, 0.90)
   - `filter_signals()` - Kategorisierung
   - `get_report_signals()` - Mit Badges
4. ‚úÖ `validators/cross_reference.py`:
   - `CrossReferenceValidator` Klasse
   - `find_corroborating_sources()` - Sucht Best√§tigungen
   - `validate_signals_cross_reference()` - Confidence-Adjustments
5. ‚úÖ `validators/llm_fact_checker.py`:
   - `LLMFactChecker` Klasse
   - Second LLM pass f√ºr Verifizierung
   - Status: verified / partially_correct / incorrect / cannot_verify
   - Confidence adjustments basierend auf Fact-Check
6. ‚úÖ Tests:
   - `tests/test_citation_validator.py` - Fake quotes detection
   - `tests/test_confidence_filter.py` - Threshold filtering
   - `tests/test_cross_reference.py` - Corroboration logic

**Deliverable:** Vollst√§ndige 7-Layer Validation funktioniert

---

### **Sprint 4: Extraction & Reporting (Tag 4-5, ~14-18h)**

**Ziel:** LLM Integration mit Validation

#### Aufgaben:
1. ‚úÖ `prompts/extract_prompt.txt`:
   - Anti-Hallucination System Prompt
   - Strikte Regeln (KEINE ERFINDUNGEN!)
   - Pflicht: verbatim_quote
   - Beispiele (gut/schlecht)
2. ‚úÖ `prompts/report_prompt.txt`:
   - Template f√ºr transparente Reports
   - Citation-Requirements [n]
   - Confidence-Level Handling
   - Datenqualit√§ts-Abschnitt
3. ‚úÖ `core/extractor.py`:
   - `extract_signals_with_grounding()` - Mit Prompt-Template
   - Company-name als Parameter
   - Numbered sources im Prompt
   - Schema-Validation (Pydantic)
4. ‚úÖ `core/report_generator.py`:
   - `generate_transparent_report()` - Mit Citations
   - Signal-Digest Vorbereitung
   - Source-Citations Liste
   - Validation-Stats Appendix
5. ‚úÖ `core/analysis_engine.py`:
   - `FactBasedAnalysisEngine` Klasse
   - `run_validated_analysis()` - Orchestriert alle Layer
   - Progress-Tracking
   - Error-Handling mit Details
   - Validation-Statistics Collection

**Deliverable:** End-to-End Pipeline funktioniert mit Validation

---

### **Sprint 5: Frontend (Tag 5-6, ~16-20h)**

**Ziel:** Neue UI mit Multi-Company Support

#### Aufgaben:
1. ‚úÖ `app.py` - Komplett √ºberarbeitet:
   - **Sidebar:**
     - Company Name Input (required)
     - Optional: Domain, Newsroom, LinkedIn
     - Lookback Days Slider
     - "Analyse starten" Button
     - EU/DE Fokus Info-Banner
     - Model-Anzeige
   - **Main Content:**
     - Welcome Screen (wenn kein Name)
     - Progress Tracking w√§hrend Analyse
     - Results Display nach Completion
     - Analysis History (DB mode)
2. ‚úÖ Progress Tracking Component:
   - Progress Bar (0-100%)
   - Status Text ("Entdecke Quellen...")
   - Completed Steps Checklist
   - Error Display
3. ‚úÖ Results Display:
   - KPI Metrics (Signale, Quellen, Rejection Rate, etc.)
   - Bericht (Markdown)
   - Signals mit Expandable Cards:
     - Headline, Fact, Metric/Value
     - Verbatim Quote (prominent)
     - Source Link
     - Confidence Badge (üü¢üü°üü†)
     - Fact-Check Status (‚úÖ‚ö†Ô∏è‚ùì‚ùå)
     - Corroboration Count
     - Corroborating Sources (expandable)
   - Filter:
     - Nach Type
     - Nach Confidence
     - Nach Fact-Check Status
     - Volltextsuche
   - Quellen-Liste (mit Links)
   - Export (CSV + JSON)
4. ‚úÖ Analysis History (DB mode):
   - Liste letzte Analysen
   - Firmenname, Datum, Status, Signal Count
   - Click to load
   - "Wiederholen" Button
   - Delete Button
5. ‚úÖ Validation Stats Dashboard:
   - Funnel-Visualisierung (wenn plotly verf√ºgbar)
   - Confidence Distribution
   - Signal Types Breakdown
6. ‚úÖ Example Data Banner:
   - Warning wenn Pernod Ricard Beispiel-Daten
   - "DEMO-DATEN" Hinweis
   - "Nicht aktuell"
7. ‚úÖ No-DB Fallback Mode:
   - Funktioniert ohne DATABASE_URL
   - Speichert in `data/{company_slug}_{date}.json`
   - Limited History (letzte 10 im data/ Ordner)

**Deliverable:** Vollst√§ndige, benutzerfreundliche UI

---

### **Sprint 6: Testing & Polish (Tag 6-7, ~12-16h)**

**Ziel:** Production-Ready Quality

#### Aufgaben:
1. ‚úÖ Unit Tests vervollst√§ndigen:
   - `tests/test_extractor.py` erweitern
   - Coverage-Report generieren
   - Edge Cases testen
2. ‚úÖ Integration Tests:
   - `tests/test_end_to_end.py` - Vollst√§ndige Pipeline
   - Test mit bekannten Firmen (Coca-Cola, Unilever)
   - Test Error-Szenarien
3. ‚úÖ Manual Testing Checklist:
   - [ ] 10 verschiedene Firmen (verschiedene Branchen)
   - [ ] Edge Cases:
     - Unbekannte Firma (keine News)
     - Firma mit Sonderzeichen
     - Sehr langer Firmenname
     - Firma mit/ohne Newsroom
   - [ ] Fact-Checking: 20 Stichproben manuell gegen Quellen pr√ºfen
   - [ ] UI/UX auf Desktop + Mobile
4. ‚úÖ Error Handling Improvements:
   - Detaillierte Fehlermeldungen
   - Recovery-Suggestions
   - Debug-Info (Traceback in Expander)
5. ‚úÖ Performance Optimierung:
   - Caching aktivieren (Streamlit @st.cache_data)
   - DB-Queries optimieren
   - Parallele Requests wo m√∂glich
6. ‚úÖ Dokumentation:
   - README.md neu schreiben
   - DEPLOYMENT.md erstellen
   - API-Docs (Docstrings)
   - Beispiel-Screenshots
7. ‚úÖ Logging:
   - Strukturiertes Logging setup
   - Log-Levels korrekt
   - Sensitive Data (API Keys) nicht loggen
8. ‚úÖ Security Review:
   - SQL Injection Prevention (parameterized queries)
   - XSS Prevention (Streamlit macht automatisch)
   - API Key nicht exposen

**Deliverable:** Production-Ready, getestet, dokumentiert

---

## üß™ Testing-Strategie

### **Unit Tests (pytest)**

```bash
# Run all tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=core --cov=validators --cov-report=html

# Specific test
pytest tests/test_citation_validator.py -v
```

### **Test Cases**

#### **Citation Validator**
- ‚úÖ Akzeptiert valide Zitate (im Text vorhanden)
- ‚úÖ Rejected fake Zitate (nicht im Text)
- ‚úÖ Fuzzy-Matching funktioniert (Tippfehler OK)
- ‚úÖ Nummerische Werte werden verifiziert
- ‚úÖ Zu kurze Zitate werden abgelehnt

#### **Confidence Filter**
- ‚úÖ Filtert Signals < 0.70 raus
- ‚úÖ Badges werden korrekt zugewiesen
- ‚úÖ Statistiken stimmen

#### **Cross-Reference**
- ‚úÖ Findet Corroborating Sources
- ‚úÖ Confidence wird geboostet
- ‚úÖ Single-Source Penalty funktioniert

#### **End-to-End**
- ‚úÖ Coca-Cola ‚Üí funktioniert
- ‚úÖ Unbekannte Firma ‚Üí Graceful Degradation
- ‚úÖ Keine OpenAI Key ‚Üí Klare Fehlermeldung

### **Manual Testing**

**Test-Firmen:**
1. Coca-Cola (gro√üe Firma, viele News)
2. Unilever (Consumer Goods)
3. LVMH (Luxury)
4. Zalando (E-Commerce Pure Play)
5. Lidl (Retail)
6. Deutsche Post DHL (Logistics)
7. Kleine lokale Firma (wenig News)
8. Startup (sehr wenig Daten)
9. B2B Firma (keine Consumer News)
10. Firma mit Umlauten (M√ºller, K√§fer)

**Fact-Checking:**
- 20 zuf√§llige Signals ausw√§hlen
- Verbatim Quote gegen Quelle pr√ºfen
- Nummerische Werte verifizieren
- Kontext korrekt wiedergegeben?

---

## üí∞ Kosten-Kalkulation

### **OpenAI API (gpt-4o-mini)**

| Komponente | Calls | Tokens | Kosten |
|------------|-------|--------|--------|
| Signal Extraction | 1-2x | ~5K input + 2K output | $0.02-0.04 |
| Report Generation | 1x | ~15K input + 3K output | $0.04-0.06 |
| Fact-Checking | 1x | ~8K input + 1K output | $0.02-0.03 |
| **Total pro Analyse** | | | **$0.08-0.13** |

**Bei verschiedenen Nutzungslevels:**
- 10 Analysen/Tag = ~$40/Monat
- 50 Analysen/Tag = ~$200/Monat
- 100 Analysen/Tag = ~$400/Monat

### **Datenbank (Supabase Free Tier)**

- ‚úÖ 500 MB Storage
- ‚úÖ Unlimited API Requests
- ‚úÖ 50K Active Users

**Kosten:** $0/Monat (kostenlos)

### **Hosting (Streamlit Cloud)**

- ‚úÖ 1 Public App
- ‚úÖ Unlimited viewers
- ‚úÖ 1 GB RAM
- ‚úÖ GitHub Integration

**Kosten:** $0/Monat (kostenlos)

### **Total Infrastruktur-Kosten**

**Fix:** $0/Monat (alles Free Tier)  
**Variabel:** OpenAI API (pay-as-you-go)

---

## üöÄ Deployment

### **Initial Setup**

1. **Supabase (optional):**
   ```
   1. Gehe zu supabase.com
   2. "Start your project" (kostenlos)
   3. Erstelle neues Projekt
   4. SQL Editor ‚Üí models.sql ausf√ºhren
   5. Kopiere DATABASE_URL aus Settings
   ```

2. **GitHub Secrets:**
   ```
   Gehe zu: Repo ‚Üí Settings ‚Üí Secrets ‚Üí Actions
   
   Neu:
   - OPENAI_API_KEY = sk-...
   - DATABASE_URL = postgresql://... (optional)
   - OPENAI_MODEL = gpt-4o-mini (optional)
   ```

3. **Streamlit Cloud:**
   ```
   1. Gehe zu share.streamlit.io
   2. "New app" ‚Üí Select Repo
   3. Main file: app.py
   4. Secrets (Advanced):
      OPENAI_API_KEY = "sk-..."
      DATABASE_URL = "postgresql://..." (optional)
   5. Deploy
   ```

### **Auto-Deployment**

Bei Push auf `main`:
- ‚úÖ Streamlit Cloud detected √Ñnderungen automatisch
- ‚úÖ Rebuild & Redeploy (~2-3 Minuten)
- ‚úÖ Keine Actions n√∂tig

### **Testing vor Production**

```bash
# Lokal testen
streamlit run app.py

# Mit DB
export DATABASE_URL="postgresql://..."
export OPENAI_API_KEY="sk-..."
streamlit run app.py

# Ohne DB (JSON Fallback)
unset DATABASE_URL
export OPENAI_API_KEY="sk-..."
streamlit run app.py
```

---

## ‚úÖ Success Criteria

### **Funktional**
- ‚úÖ User kann beliebige Firmennamen eingeben
- ‚úÖ Analyse funktioniert f√ºr mindestens 8/10 Test-Firmen
- ‚úÖ Rejection-Rate zwischen 40-60%
- ‚úÖ Durchschnittliche Confidence ‚â• 0.80
- ‚úÖ Manual Fact-Check: 18/20 Signals korrekt (90%+)
- ‚úÖ History funktioniert (wenn DB vorhanden)
- ‚úÖ JSON-Fallback funktioniert (ohne DB)
- ‚úÖ Export (CSV + JSON) funktioniert

### **Performance**
- ‚úÖ Analyse-Dauer: < 7 Minuten (gpt-4o-mini)
- ‚úÖ UI reagiert fl√ºssig
- ‚úÖ Keine Crashes bei Fehlern

### **Qualit√§t**
- ‚úÖ Code-Coverage ‚â• 60%
- ‚úÖ Alle Layer 1-6 Tests bestehen
- ‚úÖ Keine SQL Injection Vulnerabilities
- ‚úÖ Secrets nicht im Code/Logs

### **Usability**
- ‚úÖ Intuitive Bedienung (neue User k√∂nnen ohne Anleitung starten)
- ‚úÖ Klare Fehlermeldungen
- ‚úÖ Progress Tracking funktioniert
- ‚úÖ Mobile-friendly (responsive)

---

## üîÑ Post-Launch Roadmap (Optional)

### **Phase 6: Nice-to-Have Features**

**Quick Wins (1-2 Tage):**
- üìß Email-Benachrichtigung bei Completion
- üîÑ "Refresh Analysis" Button
- üìä Plotly Charts (Confidence Distribution, Signal Types)
- üåê English UI Toggle

**Medium Effort (3-5 Tage):**
- üÜö Compare Mode (Firma A vs. Firma B)
- üìÖ Scheduled Analyses (w√∂chentlich)
- üé® Custom Branding
- üìÑ PDF Export (mit weasyprint)

**Large Effort (1-2 Wochen):**
- üë• User Authentication & Workspaces
- üîå REST API
- üí≥ Credits/Usage Tracking
- ü§ñ Webhook-Integration
- üåç Multi-Language Reports

---

## üìû Support & Kontakt

**Projekt-Owner:** Jannick M√ºller  
**Repo:** GitHub (Pernod_Ricard_Agent-main ‚Üí ecommerce_intel)  
**Hosting:** Streamlit Cloud  
**Dokumentation:** Dieses Dokument

---

## üìú Changelog

### Version 2.0 (planned)
- Multi-Company Support
- 7-Layer Anti-Halluzination System
- Dual-Mode (DB + JSON)
- Analysis History
- Validation Statistics

### Version 1.0 (current)
- Hardcoded Pernod Ricard
- Basic LLM extraction
- Streamlit UI
- EU/DE Focus

---

## ‚ú® Final Notes

**Qualit√§t vor Quantit√§t:**
- Wir erwarten 40-60% Rejection-Rate
- Das ist **gewollt** - lieber weniger, daf√ºr korrekte Signale
- Validation f√§ngt Halluzinationen zuverl√§ssig ab

**Flexibilit√§t:**
- Tool funktioniert mit und ohne DB
- LLM Model einfach upgradebar
- Erweiterbar ohne Core-√Ñnderungen

**Kosteneffizienz:**
- Komplette Infrastruktur kostenlos (Free Tiers)
- Nur OpenAI API kostet (Pay-as-you-go)
- ~$0.08-0.13 pro Analyse (gpt-4o-mini)

---

**Status:** üöÄ IN PROGRESS  
**Started:** Jan 21, 2026  
**Latest Update:** Sprint 3 COMPLETE  

---

## üìä Implementation Progress

### ‚úÖ SPRINT 1: Foundation (COMPLETE)
- ‚úÖ Git repository setup
- ‚úÖ `.gitignore` with proper exclusions
- ‚úÖ Project structure created
- ‚úÖ README.md updated
- ‚úÖ Database schema (models.sql)
- ‚úÖ DB connection layer (db.py) with JSON fallback
- ‚úÖ Utility functions (url_utils.py, text_utils.py)

### ‚úÖ SPRINT 2: Multi-Source Discovery (COMPLETE)
- ‚úÖ `CompanyIntelligenceScraper` class
- ‚úÖ Google News integration
- ‚úÖ LinkedIn discovery
- ‚úÖ Newsroom auto-detection
- ‚úÖ E-commerce keyword filtering
- ‚úÖ EU region focus
- ‚úÖ Unit tests (test_scraper.py)
- ‚úÖ Basic UI for source discovery

### ‚úÖ SPRINT 3: Signal Extraction (COMPLETE) üéâ
- ‚úÖ Pydantic signal models (signal_models.py)
- ‚úÖ **Layer 2: Citation Validator** (citation_validator.py)
- ‚úÖ **Layer 4: Confidence Filter** (confidence_filter.py)
- ‚úÖ **Layer 5: Cross-Reference Validator** (cross_reference.py)
- ‚úÖ **Layer 6: LLM Fact-Checker** (llm_fact_checker.py)
- ‚úÖ Improved extraction prompts (extract_signals_v2.txt)
- ‚úÖ Updated extractor (extractor.py)
- ‚úÖ **Analysis Engine orchestration** (core/analysis_engine.py)
- ‚úÖ Complete UI with progress tracking (app.py)

**Files Created/Modified in Sprint 3:**
- NEW: `models/signal_models.py` (87 lines)
- NEW: `validators/citation_validator.py` (176 lines)
- NEW: `validators/confidence_filter.py` (134 lines)
- NEW: `validators/cross_reference.py` (146 lines)
- NEW: `validators/llm_fact_checker.py` (209 lines)
- NEW: `core/analysis_engine.py` (298 lines)
- NEW: `prompts/extract_signals_v2.txt` (73 lines)
- UPDATED: `extractor.py` (233 lines)
- UPDATED: `app.py` (428 lines)

**Total Lines Added:** ~2,100+ lines

### üöß SPRINT 4: Report Generation (PENDING)
- ‚è≥ Report templates
- ‚è≥ PDF generation
- ‚è≥ Email notifications
- ‚è≥ Scheduling

### üöß SPRINT 5: Production Polish (PENDING)
- ‚è≥ Error handling improvements
- ‚è≥ Performance optimization
- ‚è≥ Documentation
- ‚è≥ Final testing

---

## üéØ Next Steps

1. **Test on Streamlit Cloud** - Deploy und live testen
2. **Iterate based on feedback** - Bugs fixen, UX verbessern
3. **Sprint 4** - Report generation (wenn Sprint 3 stabil)

---

**Current Status:** üî• Sprint 3 deployed to GitHub  
**Git Commit:** ea71b3b - "feat: Sprint 3 complete - Signal extraction with 7-layer anti-hallucination"  
**Deployed URL:** https://github.com/revoic/e-commerce_analyse  

üöÄ **Ready for live testing!**
